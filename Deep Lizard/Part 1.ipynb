{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental drugs scenario\n",
    "for i in range(50):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    # The 5% of older individuals who didn't experience side effects\n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    # The majority of younger individuals\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    # The majority of older individuals\n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 98,\n",
       " 22,\n",
       " 83,\n",
       " 55,\n",
       " 96,\n",
       " 32,\n",
       " 65,\n",
       " 64,\n",
       " 99,\n",
       " 46,\n",
       " 98,\n",
       " 60,\n",
       " 94,\n",
       " 64,\n",
       " 98,\n",
       " 30,\n",
       " 72,\n",
       " 52,\n",
       " 92,\n",
       " 48,\n",
       " 79,\n",
       " 52,\n",
       " 91,\n",
       " 57,\n",
       " 83,\n",
       " 26,\n",
       " 88,\n",
       " 37,\n",
       " 72,\n",
       " 34,\n",
       " 67,\n",
       " 49,\n",
       " 98,\n",
       " 60,\n",
       " 72,\n",
       " 13,\n",
       " 74,\n",
       " 15,\n",
       " 84,\n",
       " 63,\n",
       " 97,\n",
       " 32,\n",
       " 88,\n",
       " 57,\n",
       " 76,\n",
       " 27,\n",
       " 86,\n",
       " 22,\n",
       " 88,\n",
       " 48,\n",
       " 85,\n",
       " 48,\n",
       " 85,\n",
       " 58,\n",
       " 70,\n",
       " 15,\n",
       " 99,\n",
       " 53,\n",
       " 74,\n",
       " 35,\n",
       " 77,\n",
       " 47,\n",
       " 97,\n",
       " 48,\n",
       " 90,\n",
       " 22,\n",
       " 72,\n",
       " 30,\n",
       " 99,\n",
       " 59,\n",
       " 73,\n",
       " 15,\n",
       " 95,\n",
       " 49,\n",
       " 88,\n",
       " 46,\n",
       " 96,\n",
       " 27,\n",
       " 67,\n",
       " 56,\n",
       " 100,\n",
       " 31,\n",
       " 94,\n",
       " 22,\n",
       " 86,\n",
       " 25,\n",
       " 82,\n",
       " 48,\n",
       " 94,\n",
       " 27,\n",
       " 91,\n",
       " 36,\n",
       " 73,\n",
       " 27,\n",
       " 66,\n",
       " 44,\n",
       " 83,\n",
       " 32,\n",
       " 74,\n",
       " 41,\n",
       " 70,\n",
       " 15,\n",
       " 83,\n",
       " 20,\n",
       " 67,\n",
       " 51,\n",
       " 90,\n",
       " 19,\n",
       " 72,\n",
       " 64,\n",
       " 70,\n",
       " 53,\n",
       " 90,\n",
       " 44,\n",
       " 87,\n",
       " 22,\n",
       " 88,\n",
       " 31,\n",
       " 85,\n",
       " 20,\n",
       " 69,\n",
       " 40,\n",
       " 95,\n",
       " 15,\n",
       " 84,\n",
       " 15,\n",
       " 86,\n",
       " 28,\n",
       " 84,\n",
       " 19,\n",
       " 82,\n",
       " 17,\n",
       " 86,\n",
       " 25,\n",
       " 82,\n",
       " 64,\n",
       " 95,\n",
       " 35,\n",
       " 72,\n",
       " 44,\n",
       " 70,\n",
       " 60,\n",
       " 87,\n",
       " 13,\n",
       " 90,\n",
       " 13,\n",
       " 90,\n",
       " 52,\n",
       " 69,\n",
       " 46,\n",
       " 94,\n",
       " 63,\n",
       " 77,\n",
       " 19,\n",
       " 70,\n",
       " 23,\n",
       " 84,\n",
       " 42,\n",
       " 96,\n",
       " 52,\n",
       " 82,\n",
       " 52,\n",
       " 66,\n",
       " 43,\n",
       " 86,\n",
       " 16,\n",
       " 93,\n",
       " 48,\n",
       " 94,\n",
       " 38,\n",
       " 97,\n",
       " 62,\n",
       " 89,\n",
       " 55,\n",
       " 89,\n",
       " 64,\n",
       " 99,\n",
       " 28,\n",
       " 66,\n",
       " 48,\n",
       " 69,\n",
       " 31,\n",
       " 92,\n",
       " 50,\n",
       " 75,\n",
       " 56,\n",
       " 92,\n",
       " 20,\n",
       " 84,\n",
       " 31,\n",
       " 85,\n",
       " 17,\n",
       " 66,\n",
       " 63,\n",
       " 85,\n",
       " 33,\n",
       " 88,\n",
       " 40,\n",
       " 70,\n",
       " 27,\n",
       " 73,\n",
       " 59,\n",
       " 72,\n",
       " 30,\n",
       " 87,\n",
       " 31,\n",
       " 100,\n",
       " 17,\n",
       " 98,\n",
       " 33,\n",
       " 73,\n",
       " 36,\n",
       " 99,\n",
       " 21,\n",
       " 86,\n",
       " 25,\n",
       " 95,\n",
       " 24,\n",
       " 83,\n",
       " 24,\n",
       " 72,\n",
       " 54,\n",
       " 97,\n",
       " 25,\n",
       " 65,\n",
       " 19,\n",
       " 80,\n",
       " 24,\n",
       " 85,\n",
       " 64,\n",
       " 88,\n",
       " 64,\n",
       " 95,\n",
       " 26,\n",
       " 86,\n",
       " 53,\n",
       " 93,\n",
       " 56,\n",
       " 85,\n",
       " 47,\n",
       " 82,\n",
       " 38,\n",
       " 71,\n",
       " 20,\n",
       " 74,\n",
       " 50,\n",
       " 100,\n",
       " 19,\n",
       " 71,\n",
       " 44,\n",
       " 85,\n",
       " 30,\n",
       " 79,\n",
       " 59,\n",
       " 90,\n",
       " 58,\n",
       " 94,\n",
       " 42,\n",
       " 85,\n",
       " 46,\n",
       " 74,\n",
       " 59,\n",
       " 100,\n",
       " 59,\n",
       " 94,\n",
       " 36,\n",
       " 96,\n",
       " 31,\n",
       " 95,\n",
       " 14,\n",
       " 98,\n",
       " 29,\n",
       " 76,\n",
       " 62,\n",
       " 91,\n",
       " 19,\n",
       " 96,\n",
       " 21,\n",
       " 75,\n",
       " 43,\n",
       " 81,\n",
       " 20,\n",
       " 67,\n",
       " 19,\n",
       " 73,\n",
       " 53,\n",
       " 79,\n",
       " 59,\n",
       " 90,\n",
       " 53,\n",
       " 84,\n",
       " 46,\n",
       " 90,\n",
       " 33,\n",
       " 98,\n",
       " 24,\n",
       " 80,\n",
       " 22,\n",
       " 83,\n",
       " 63,\n",
       " 86,\n",
       " 63,\n",
       " 78,\n",
       " 44,\n",
       " 87,\n",
       " 53,\n",
       " 94,\n",
       " 54,\n",
       " 99,\n",
       " 41,\n",
       " 70,\n",
       " 24,\n",
       " 65,\n",
       " 36,\n",
       " 83,\n",
       " 47,\n",
       " 95,\n",
       " 46,\n",
       " 67,\n",
       " 32,\n",
       " 79,\n",
       " 34,\n",
       " 79,\n",
       " 27,\n",
       " 97,\n",
       " 42,\n",
       " 69,\n",
       " 44,\n",
       " 96,\n",
       " 25,\n",
       " 82,\n",
       " 35,\n",
       " 83,\n",
       " 54,\n",
       " 93,\n",
       " 18,\n",
       " 94,\n",
       " 61,\n",
       " 69,\n",
       " 31,\n",
       " 91,\n",
       " 48,\n",
       " 81,\n",
       " 13,\n",
       " 91,\n",
       " 46,\n",
       " 71,\n",
       " 62,\n",
       " 89,\n",
       " 39,\n",
       " 72,\n",
       " 47,\n",
       " 67,\n",
       " 62,\n",
       " 92,\n",
       " 35,\n",
       " 92,\n",
       " 57,\n",
       " 92,\n",
       " 54,\n",
       " 100,\n",
       " 21,\n",
       " 89,\n",
       " 56,\n",
       " 65,\n",
       " 28,\n",
       " 98,\n",
       " 19,\n",
       " 68,\n",
       " 54,\n",
       " 72,\n",
       " 53,\n",
       " 76,\n",
       " 28,\n",
       " 86,\n",
       " 59,\n",
       " 96,\n",
       " 13,\n",
       " 71,\n",
       " 58,\n",
       " 92,\n",
       " 31,\n",
       " 89,\n",
       " 43,\n",
       " 75,\n",
       " 21,\n",
       " 92,\n",
       " 17,\n",
       " 99,\n",
       " 34,\n",
       " 75,\n",
       " 30,\n",
       " 90,\n",
       " 59,\n",
       " 90,\n",
       " 23,\n",
       " 99,\n",
       " 50,\n",
       " 92,\n",
       " 32,\n",
       " 79,\n",
       " 30,\n",
       " 100,\n",
       " 16,\n",
       " 90,\n",
       " 58,\n",
       " 70,\n",
       " 37,\n",
       " 92,\n",
       " 24,\n",
       " 99,\n",
       " 44,\n",
       " 67,\n",
       " 40,\n",
       " 81,\n",
       " 30,\n",
       " 93,\n",
       " 57,\n",
       " 65,\n",
       " 28,\n",
       " 88,\n",
       " 32,\n",
       " 65,\n",
       " 51,\n",
       " 74,\n",
       " 32,\n",
       " 79,\n",
       " 33,\n",
       " 94,\n",
       " 31,\n",
       " 68,\n",
       " 35,\n",
       " 93,\n",
       " 25,\n",
       " 77,\n",
       " 54,\n",
       " 85,\n",
       " 62,\n",
       " 88,\n",
       " 29,\n",
       " 89,\n",
       " 14,\n",
       " 84,\n",
       " 43,\n",
       " 98,\n",
       " 64,\n",
       " 82,\n",
       " 35,\n",
       " 67,\n",
       " 55,\n",
       " 89,\n",
       " 45,\n",
       " 98,\n",
       " 31,\n",
       " 70,\n",
       " 17,\n",
       " 67,\n",
       " 36,\n",
       " 83,\n",
       " 35,\n",
       " 84,\n",
       " 32,\n",
       " 99,\n",
       " 43,\n",
       " 100,\n",
       " 28,\n",
       " 98,\n",
       " 24,\n",
       " 88,\n",
       " 30,\n",
       " 71,\n",
       " 21,\n",
       " 81,\n",
       " 20,\n",
       " 69,\n",
       " 33,\n",
       " 68,\n",
       " 55,\n",
       " 77,\n",
       " 27,\n",
       " 79,\n",
       " 37,\n",
       " 100,\n",
       " 22,\n",
       " 70,\n",
       " 18,\n",
       " 88,\n",
       " 56,\n",
       " 81,\n",
       " 27,\n",
       " 93,\n",
       " 59,\n",
       " 73,\n",
       " 51,\n",
       " 79,\n",
       " 43,\n",
       " 86,\n",
       " 64,\n",
       " 80,\n",
       " 31,\n",
       " 94,\n",
       " 33,\n",
       " 90,\n",
       " 34,\n",
       " 70,\n",
       " 28,\n",
       " 92,\n",
       " 51,\n",
       " 66,\n",
       " 22,\n",
       " 65,\n",
       " 62,\n",
       " 95,\n",
       " 57,\n",
       " 74,\n",
       " 43,\n",
       " 77,\n",
       " 17,\n",
       " 75,\n",
       " 25,\n",
       " 87,\n",
       " 14,\n",
       " 90,\n",
       " 21,\n",
       " 86,\n",
       " 13,\n",
       " 84,\n",
       " 17,\n",
       " 73,\n",
       " 36,\n",
       " 75,\n",
       " 22,\n",
       " 83,\n",
       " 20,\n",
       " 94,\n",
       " 25,\n",
       " 89,\n",
       " 60,\n",
       " 71,\n",
       " 21,\n",
       " 77,\n",
       " 48,\n",
       " 76,\n",
       " 23,\n",
       " 83,\n",
       " 40,\n",
       " 94,\n",
       " 29,\n",
       " 89,\n",
       " 45,\n",
       " 89,\n",
       " 54,\n",
       " 91,\n",
       " 34,\n",
       " 87,\n",
       " 14,\n",
       " 67,\n",
       " 63,\n",
       " 93,\n",
       " 46,\n",
       " 74,\n",
       " 44,\n",
       " 92,\n",
       " 50,\n",
       " 98,\n",
       " 24,\n",
       " 78,\n",
       " 27,\n",
       " 81,\n",
       " 52,\n",
       " 88,\n",
       " 40,\n",
       " 66,\n",
       " 55,\n",
       " 84,\n",
       " 20,\n",
       " 73,\n",
       " 55,\n",
       " 89,\n",
       " 28,\n",
       " 91,\n",
       " 41,\n",
       " 80,\n",
       " 19,\n",
       " 69,\n",
       " 62,\n",
       " 86,\n",
       " 57,\n",
       " 99,\n",
       " 56,\n",
       " 91,\n",
       " 32,\n",
       " 66,\n",
       " 30,\n",
       " 85,\n",
       " 24,\n",
       " 91,\n",
       " 35,\n",
       " 75,\n",
       " 27,\n",
       " 100,\n",
       " 34,\n",
       " 89,\n",
       " 55,\n",
       " 85,\n",
       " 33,\n",
       " 77,\n",
       " 32,\n",
       " 83,\n",
       " 31,\n",
       " 87,\n",
       " 34,\n",
       " 84,\n",
       " 26,\n",
       " 68,\n",
       " 25,\n",
       " 76,\n",
       " 42,\n",
       " 96,\n",
       " 34,\n",
       " 73,\n",
       " 59,\n",
       " 85,\n",
       " 44,\n",
       " 70,\n",
       " 41,\n",
       " 95,\n",
       " 58,\n",
       " 72,\n",
       " 13,\n",
       " 69,\n",
       " 44,\n",
       " 91,\n",
       " 20,\n",
       " 95,\n",
       " 51,\n",
       " 77,\n",
       " 20,\n",
       " 69,\n",
       " 28,\n",
       " 92,\n",
       " 39,\n",
       " 77,\n",
       " 39,\n",
       " 70,\n",
       " 24,\n",
       " 71,\n",
       " 52,\n",
       " 74,\n",
       " 55,\n",
       " 82,\n",
       " 35,\n",
       " 82,\n",
       " 63,\n",
       " 94,\n",
       " 47,\n",
       " 77,\n",
       " 41,\n",
       " 72,\n",
       " 34,\n",
       " 74,\n",
       " 47,\n",
       " 79,\n",
       " 28,\n",
       " 97,\n",
       " 22,\n",
       " 91,\n",
       " 60,\n",
       " 83,\n",
       " 49,\n",
       " 96,\n",
       " 54,\n",
       " 82,\n",
       " 52,\n",
       " 82,\n",
       " 43,\n",
       " 76,\n",
       " 43,\n",
       " 78,\n",
       " 63,\n",
       " 72,\n",
       " 28,\n",
       " 94,\n",
       " 63,\n",
       " 86,\n",
       " 39,\n",
       " 76,\n",
       " 64,\n",
       " 99,\n",
       " 26,\n",
       " 74,\n",
       " 21,\n",
       " 93,\n",
       " 38,\n",
       " 77,\n",
       " 35,\n",
       " 97,\n",
       " 30,\n",
       " 91,\n",
       " 38,\n",
       " 99,\n",
       " 14,\n",
       " 74,\n",
       " 19,\n",
       " 93,\n",
       " 59,\n",
       " 85,\n",
       " 49,\n",
       " 96,\n",
       " 44,\n",
       " 93,\n",
       " 22,\n",
       " 73,\n",
       " 56,\n",
       " 84,\n",
       " 17,\n",
       " 82,\n",
       " 64,\n",
       " 100,\n",
       " 51,\n",
       " 76,\n",
       " 14,\n",
       " 79,\n",
       " 25,\n",
       " 75,\n",
       " 29,\n",
       " 88,\n",
       " 29,\n",
       " 85,\n",
       " 13,\n",
       " 77,\n",
       " 32,\n",
       " 68,\n",
       " 18,\n",
       " 99,\n",
       " 17,\n",
       " 72,\n",
       " 53,\n",
       " 65,\n",
       " 28,\n",
       " 76,\n",
       " 42,\n",
       " 70,\n",
       " 25,\n",
       " 75,\n",
       " 50,\n",
       " 81,\n",
       " 53,\n",
       " 86,\n",
       " 56,\n",
       " 77,\n",
       " 28,\n",
       " 83,\n",
       " 32,\n",
       " 76,\n",
       " 35,\n",
       " 74,\n",
       " 20,\n",
       " 74,\n",
       " 38,\n",
       " 92,\n",
       " 40,\n",
       " 79,\n",
       " 48,\n",
       " 85,\n",
       " 62,\n",
       " 72,\n",
       " 39,\n",
       " 97,\n",
       " 15,\n",
       " 65,\n",
       " 61,\n",
       " 77,\n",
       " 16,\n",
       " 67,\n",
       " 43,\n",
       " 66,\n",
       " 62,\n",
       " 96,\n",
       " 27,\n",
       " 78,\n",
       " 21,\n",
       " 72,\n",
       " 60,\n",
       " 68,\n",
       " 50,\n",
       " 89,\n",
       " 63,\n",
       " 73,\n",
       " 26,\n",
       " 65,\n",
       " 26,\n",
       " 98,\n",
       " 43,\n",
       " 93,\n",
       " 24,\n",
       " 79,\n",
       " 34,\n",
       " 75,\n",
       " 36,\n",
       " 97,\n",
       " 58,\n",
       " 92,\n",
       " 13,\n",
       " 66,\n",
       " 18,\n",
       " 67,\n",
       " 41,\n",
       " 81,\n",
       " 15,\n",
       " 86,\n",
       " 27,\n",
       " 65,\n",
       " 47,\n",
       " 100,\n",
       " 41,\n",
       " 80,\n",
       " 14,\n",
       " 83,\n",
       " 51,\n",
       " 73,\n",
       " 51,\n",
       " 81,\n",
       " 47,\n",
       " 76,\n",
       " 50,\n",
       " 76,\n",
       " 51,\n",
       " 85,\n",
       " 44,\n",
       " 84,\n",
       " 18,\n",
       " 69,\n",
       " 60,\n",
       " 71,\n",
       " 28,\n",
       " 82,\n",
       " 32,\n",
       " 87,\n",
       " 48,\n",
       " 87,\n",
       " 34,\n",
       " 92,\n",
       " 60,\n",
       " 79,\n",
       " 40,\n",
       " 89,\n",
       " 34,\n",
       " 73,\n",
       " 58,\n",
       " 83,\n",
       " 13,\n",
       " 94,\n",
       " 40,\n",
       " 75,\n",
       " 16,\n",
       " 99,\n",
       " 14,\n",
       " 66,\n",
       " 58,\n",
       " 82,\n",
       " 20,\n",
       " 66,\n",
       " 38,\n",
       " 92,\n",
       " 41,\n",
       " 89,\n",
       " 48,\n",
       " 83,\n",
       " 58,\n",
       " 85,\n",
       " 31,\n",
       " 75,\n",
       " 24,\n",
       " 72,\n",
       " 32,\n",
       " 78,\n",
       " 57,\n",
       " 68,\n",
       " 60,\n",
       " 88,\n",
       " 21,\n",
       " 85,\n",
       " 16,\n",
       " 81,\n",
       " 55,\n",
       " 96,\n",
       " 31,\n",
       " 86,\n",
       " 46,\n",
       " 89,\n",
       " 30,\n",
       " 72,\n",
       " 43,\n",
       " 95,\n",
       " 28,\n",
       " 89,\n",
       " 48,\n",
       " 73,\n",
       " 22,\n",
       " 70,\n",
       " 28,\n",
       " 76,\n",
       " 40,\n",
       " 79,\n",
       " 52,\n",
       " 72,\n",
       " 46,\n",
       " 76,\n",
       " 50,\n",
       " 73,\n",
       " 34,\n",
       " 68,\n",
       " 27,\n",
       " 80,\n",
       " 13,\n",
       " 93,\n",
       " 30,\n",
       " 77,\n",
       " 59,\n",
       " 76,\n",
       " 21,\n",
       " 66,\n",
       " 25,\n",
       " 95,\n",
       " 55,\n",
       " 77,\n",
       " 37,\n",
       " 78,\n",
       " 18,\n",
       " 100,\n",
       " 53,\n",
       " 80,\n",
       " 62,\n",
       " 70,\n",
       " 55,\n",
       " 74,\n",
       " 48,\n",
       " 92,\n",
       " 35,\n",
       " 66,\n",
       " 58,\n",
       " 65,\n",
       " 57,\n",
       " 81,\n",
       " 22,\n",
       " 83,\n",
       " 47,\n",
       " 94,\n",
       " 14,\n",
       " 69,\n",
       " 46,\n",
       " 73,\n",
       " 23,\n",
       " 95,\n",
       " 21,\n",
       " 88,\n",
       " 36,\n",
       " 82,\n",
       " 58,\n",
       " 77,\n",
       " 13,\n",
       " 83,\n",
       " 43,\n",
       " 76,\n",
       " 45,\n",
       " 77,\n",
       " 27,\n",
       " 86,\n",
       " 37,\n",
       " 87,\n",
       " 37,\n",
       " 92,\n",
       " 16,\n",
       " 68,\n",
       " 37,\n",
       " 99,\n",
       " 31,\n",
       " 91,\n",
       " 48,\n",
       " 76,\n",
       " 14,\n",
       " 69,\n",
       " 47,\n",
       " 74,\n",
       " 19,\n",
       " 70,\n",
       " 16,\n",
       " 88,\n",
       " 63,\n",
       " 67,\n",
       " 29,\n",
       " 87,\n",
       " 60,\n",
       " 83,\n",
       " 56,\n",
       " 94,\n",
       " 49,\n",
       " 76,\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View train_samples\n",
    "train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into numpy arrays\n",
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the two lists\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81],\n",
       "       [34],\n",
       "       [66],\n",
       "       ...,\n",
       "       [85],\n",
       "       [92],\n",
       "       [20]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the ages from a scale of 13 to 100 to 0 to 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Fit-transform doesn't accept 1-d data\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7816092 ],\n",
       "       [0.24137931],\n",
       "       [0.6091954 ],\n",
       "       ...,\n",
       "       [0.82758621],\n",
       "       [0.90804598],\n",
       "       [0.08045977]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the scaled data\n",
    "scaled_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation=\"relu\"),\n",
    "    Dense(units=32, activation=\"relu\"),\n",
    "    Dense(units=2, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of input layer\n",
    "scaled_train_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2100/2100 - 2s - loss: 0.6933 - acc: 0.5843\n",
      "Epoch 2/30\n",
      "2100/2100 - 1s - loss: 0.6627 - acc: 0.6190\n",
      "Epoch 3/30\n",
      "2100/2100 - 1s - loss: 0.6278 - acc: 0.6938\n",
      "Epoch 4/30\n",
      "2100/2100 - 1s - loss: 0.5802 - acc: 0.7900\n",
      "Epoch 5/30\n",
      "2100/2100 - 1s - loss: 0.5398 - acc: 0.8157\n",
      "Epoch 6/30\n",
      "2100/2100 - 1s - loss: 0.5048 - acc: 0.8352\n",
      "Epoch 7/30\n",
      "2100/2100 - 1s - loss: 0.4717 - acc: 0.8495\n",
      "Epoch 8/30\n",
      "2100/2100 - 1s - loss: 0.4412 - acc: 0.8705\n",
      "Epoch 9/30\n",
      "2100/2100 - 1s - loss: 0.4137 - acc: 0.8805\n",
      "Epoch 10/30\n",
      "2100/2100 - 1s - loss: 0.3897 - acc: 0.8881\n",
      "Epoch 11/30\n",
      "2100/2100 - 1s - loss: 0.3690 - acc: 0.9019\n",
      "Epoch 12/30\n",
      "2100/2100 - 1s - loss: 0.3519 - acc: 0.9019\n",
      "Epoch 13/30\n",
      "2100/2100 - 1s - loss: 0.3377 - acc: 0.9071\n",
      "Epoch 14/30\n",
      "2100/2100 - 1s - loss: 0.3258 - acc: 0.9143\n",
      "Epoch 15/30\n",
      "2100/2100 - 1s - loss: 0.3158 - acc: 0.9119\n",
      "Epoch 16/30\n",
      "2100/2100 - 1s - loss: 0.3072 - acc: 0.9181\n",
      "Epoch 17/30\n",
      "2100/2100 - 1s - loss: 0.3001 - acc: 0.9171\n",
      "Epoch 18/30\n",
      "2100/2100 - 1s - loss: 0.2943 - acc: 0.9195\n",
      "Epoch 19/30\n",
      "2100/2100 - 1s - loss: 0.2892 - acc: 0.9195\n",
      "Epoch 20/30\n",
      "2100/2100 - 1s - loss: 0.2849 - acc: 0.9205\n",
      "Epoch 21/30\n",
      "2100/2100 - 1s - loss: 0.2814 - acc: 0.9267\n",
      "Epoch 22/30\n",
      "2100/2100 - 1s - loss: 0.2781 - acc: 0.9233\n",
      "Epoch 23/30\n",
      "2100/2100 - 1s - loss: 0.2753 - acc: 0.9238\n",
      "Epoch 24/30\n",
      "2100/2100 - 1s - loss: 0.2731 - acc: 0.9314\n",
      "Epoch 25/30\n",
      "2100/2100 - 1s - loss: 0.2709 - acc: 0.9324\n",
      "Epoch 26/30\n",
      "2100/2100 - 1s - loss: 0.2690 - acc: 0.9271\n",
      "Epoch 27/30\n",
      "2100/2100 - 1s - loss: 0.2674 - acc: 0.9324\n",
      "Epoch 28/30\n",
      "2100/2100 - 1s - loss: 0.2659 - acc: 0.9305\n",
      "Epoch 29/30\n",
      "2100/2100 - 1s - loss: 0.2646 - acc: 0.9348\n",
      "Epoch 30/30\n",
      "2100/2100 - 1s - loss: 0.2635 - acc: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e774308c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/30\n",
      "1890/1890 - 1s - loss: 0.2636 - acc: 0.9333 - val_loss: 0.2526 - val_acc: 0.9333\n",
      "Epoch 2/30\n",
      "1890/1890 - 1s - loss: 0.2627 - acc: 0.9323 - val_loss: 0.2512 - val_acc: 0.9333\n",
      "Epoch 3/30\n",
      "1890/1890 - 1s - loss: 0.2620 - acc: 0.9339 - val_loss: 0.2498 - val_acc: 0.9524\n",
      "Epoch 4/30\n",
      "1890/1890 - 1s - loss: 0.2614 - acc: 0.9354 - val_loss: 0.2491 - val_acc: 0.9333\n",
      "Epoch 5/30\n",
      "1890/1890 - 1s - loss: 0.2606 - acc: 0.9333 - val_loss: 0.2484 - val_acc: 0.9333\n",
      "Epoch 6/30\n",
      "1890/1890 - 1s - loss: 0.2601 - acc: 0.9328 - val_loss: 0.2478 - val_acc: 0.9333\n",
      "Epoch 7/30\n",
      "1890/1890 - 2s - loss: 0.2596 - acc: 0.9328 - val_loss: 0.2466 - val_acc: 0.9333\n",
      "Epoch 8/30\n",
      "1890/1890 - 1s - loss: 0.2592 - acc: 0.9360 - val_loss: 0.2460 - val_acc: 0.9333\n",
      "Epoch 9/30\n",
      "1890/1890 - 2s - loss: 0.2587 - acc: 0.9328 - val_loss: 0.2451 - val_acc: 0.9524\n",
      "Epoch 10/30\n",
      "1890/1890 - 2s - loss: 0.2580 - acc: 0.9423 - val_loss: 0.2452 - val_acc: 0.9333\n",
      "Epoch 11/30\n",
      "1890/1890 - 2s - loss: 0.2579 - acc: 0.9360 - val_loss: 0.2451 - val_acc: 0.9333\n",
      "Epoch 12/30\n",
      "1890/1890 - 1s - loss: 0.2574 - acc: 0.9339 - val_loss: 0.2432 - val_acc: 0.9524\n",
      "Epoch 13/30\n",
      "1890/1890 - 1s - loss: 0.2571 - acc: 0.9339 - val_loss: 0.2431 - val_acc: 0.9333\n",
      "Epoch 14/30\n",
      "1890/1890 - 1s - loss: 0.2568 - acc: 0.9402 - val_loss: 0.2421 - val_acc: 0.9524\n",
      "Epoch 15/30\n",
      "1890/1890 - 1s - loss: 0.2562 - acc: 0.9392 - val_loss: 0.2419 - val_acc: 0.9524\n",
      "Epoch 16/30\n",
      "1890/1890 - 1s - loss: 0.2560 - acc: 0.9386 - val_loss: 0.2414 - val_acc: 0.9524\n",
      "Epoch 17/30\n",
      "1890/1890 - 1s - loss: 0.2554 - acc: 0.9429 - val_loss: 0.2415 - val_acc: 0.9333\n",
      "Epoch 18/30\n",
      "1890/1890 - 1s - loss: 0.2551 - acc: 0.9381 - val_loss: 0.2410 - val_acc: 0.9333\n",
      "Epoch 19/30\n",
      "1890/1890 - 1s - loss: 0.2546 - acc: 0.9365 - val_loss: 0.2396 - val_acc: 0.9524\n",
      "Epoch 20/30\n",
      "1890/1890 - 1s - loss: 0.2544 - acc: 0.9397 - val_loss: 0.2393 - val_acc: 0.9524\n",
      "Epoch 21/30\n",
      "1890/1890 - 1s - loss: 0.2541 - acc: 0.9429 - val_loss: 0.2395 - val_acc: 0.9524\n",
      "Epoch 22/30\n",
      "1890/1890 - 1s - loss: 0.2538 - acc: 0.9418 - val_loss: 0.2394 - val_acc: 0.9524\n",
      "Epoch 23/30\n",
      "1890/1890 - 1s - loss: 0.2533 - acc: 0.9365 - val_loss: 0.2383 - val_acc: 0.9524\n",
      "Epoch 24/30\n",
      "1890/1890 - 1s - loss: 0.2530 - acc: 0.9418 - val_loss: 0.2383 - val_acc: 0.9524\n",
      "Epoch 25/30\n",
      "1890/1890 - 1s - loss: 0.2527 - acc: 0.9429 - val_loss: 0.2385 - val_acc: 0.9524\n",
      "Epoch 26/30\n",
      "1890/1890 - 1s - loss: 0.2524 - acc: 0.9392 - val_loss: 0.2375 - val_acc: 0.9524\n",
      "Epoch 27/30\n",
      "1890/1890 - 1s - loss: 0.2521 - acc: 0.9429 - val_loss: 0.2373 - val_acc: 0.9524\n",
      "Epoch 28/30\n",
      "1890/1890 - 1s - loss: 0.2519 - acc: 0.9429 - val_loss: 0.2368 - val_acc: 0.9524\n",
      "Epoch 29/30\n",
      "1890/1890 - 1s - loss: 0.2515 - acc: 0.9429 - val_loss: 0.2365 - val_acc: 0.9524\n",
      "Epoch 30/30\n",
      "1890/1890 - 1s - loss: 0.2513 - acc: 0.9429 - val_loss: 0.2362 - val_acc: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e786075c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get metrics for validation set\n",
    "model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental drugs scenario\n",
    "for i in range(10):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    # The 5% of older individuals who didn't experience side effects\n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    # The majority of younger individuals\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    # The majority of older individuals\n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into numpy arrays\n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the two lists\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
    "\n",
    "# Scale the data features\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07773572 0.9222643 ]\n",
      "[0.9747049  0.02529501]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.94359726 0.05640272]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.04181827 0.95818174]\n",
      "[0.11283044 0.8871696 ]\n",
      "[0.936816   0.06318399]\n",
      "[0.9740906  0.02590937]\n",
      "[0.9742066 0.0257934]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.16137594 0.83862406]\n",
      "[0.96922505 0.03077491]\n",
      "[0.9708439 0.0291561]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.9739742  0.02602585]\n",
      "[0.7032138  0.29678616]\n",
      "[0.975155   0.02484501]\n",
      "[0.97493094 0.02506902]\n",
      "[0.97498715 0.02501284]\n",
      "[0.08384287 0.9161572 ]\n",
      "[0.894353   0.10564696]\n",
      "[0.02209866 0.97790134]\n",
      "[0.03864308 0.9613569 ]\n",
      "[0.9675194  0.03248058]\n",
      "[0.96382993 0.03617002]\n",
      "[0.10485352 0.8951464 ]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.9494277  0.05057232]\n",
      "[0.04181827 0.95818174]\n",
      "[0.0203889  0.97961116]\n",
      "[0.96382993 0.03617002]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.97373974 0.02626033]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.5224995  0.47750047]\n",
      "[0.97504324 0.02495677]\n",
      "[0.04181827 0.95818174]\n",
      "[0.9740906  0.02590937]\n",
      "[0.05290589 0.94709414]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.05290589 0.94709414]\n",
      "[0.96922505 0.03077491]\n",
      "[0.7771171  0.22288294]\n",
      "[0.97521067 0.02478931]\n",
      "[0.97453415 0.0254658 ]\n",
      "[0.9746482  0.02535182]\n",
      "[0.9675194  0.03248058]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.11283044 0.8871696 ]\n",
      "[0.97373974 0.02626033]\n",
      "[0.9708439 0.0291561]\n",
      "[0.97493094 0.02506902]\n",
      "[0.33569655 0.6643035 ]\n",
      "[0.9731513  0.02684869]\n",
      "[0.03864308 0.9613569 ]\n",
      "[0.9750992  0.02490082]\n",
      "[0.908185   0.09181502]\n",
      "[0.01734913 0.9826508 ]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.96147114 0.03852889]\n",
      "[0.03864308 0.9613569 ]\n",
      "[0.25562602 0.744374  ]\n",
      "[0.97373974 0.02626033]\n",
      "[0.97476166 0.02523833]\n",
      "[0.97476166 0.02523833]\n",
      "[0.7771171  0.22288294]\n",
      "[0.01880888 0.9811911 ]\n",
      "[0.9748746  0.02512534]\n",
      "[0.97245514 0.02754483]\n",
      "[0.9739742  0.02602585]\n",
      "[0.10485352 0.8951464 ]\n",
      "[0.908185   0.09181502]\n",
      "[0.9736216  0.02637834]\n",
      "[0.04181827 0.95818174]\n",
      "[0.0329734  0.96702665]\n",
      "[0.01600082 0.9839992 ]\n",
      "[0.9494277  0.05057232]\n",
      "[0.66139156 0.33860835]\n",
      "[0.03570004 0.9642999 ]\n",
      "[0.0203889  0.97961116]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.9675194  0.03248058]\n",
      "[0.936816   0.06318399]\n",
      "[0.97443706 0.02556298]\n",
      "[0.97443706 0.02556298]\n",
      "[0.9292805  0.07071944]\n",
      "[0.02209866 0.97790134]\n",
      "[0.0203889  0.97961116]\n",
      "[0.0203889  0.97961116]\n",
      "[0.10485352 0.8951464 ]\n",
      "[0.01880888 0.9811911 ]\n",
      "[0.0203889  0.97961116]\n",
      "[0.908185   0.09181502]\n",
      "[0.18921436 0.81078565]\n",
      "[0.9750992  0.02490082]\n",
      "[0.03864308 0.9613569 ]\n",
      "[0.10485352 0.8951464 ]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.570332   0.42966804]\n",
      "[0.97385716 0.02614283]\n",
      "[0.29407382 0.70592624]\n",
      "[0.96382993 0.03617002]\n",
      "[0.9675194  0.03248058]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.97476166 0.02523833]\n",
      "[0.9748746  0.02512534]\n",
      "[0.94359726 0.05640272]\n",
      "[0.29407382 0.70592624]\n",
      "[0.96147114 0.03852889]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.7771171  0.22288294]\n",
      "[0.7771171  0.22288294]\n",
      "[0.0329734  0.96702665]\n",
      "[0.9752662  0.02473373]\n",
      "[0.9750992  0.02490082]\n",
      "[0.975155   0.02484501]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.97385716 0.02614283]\n",
      "[0.12154609 0.87845397]\n",
      "[0.894353   0.10564696]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.04181827 0.95818174]\n",
      "[0.04181827 0.95818174]\n",
      "[0.9750992  0.02490082]\n",
      "[0.3800386  0.61996144]\n",
      "[0.3800386  0.61996144]\n",
      "[0.12154609 0.87845397]\n",
      "[0.33569655 0.6643035 ]\n",
      "[0.96922505 0.03077491]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.12154609 0.87845397]\n",
      "[0.97459126 0.02540874]\n",
      "[0.9717415  0.02825852]\n",
      "[0.08384287 0.9161572 ]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.975155   0.02484501]\n",
      "[0.13736773 0.8626323 ]\n",
      "[0.09737864 0.9026213 ]\n",
      "[0.06178394 0.9382161 ]\n",
      "[0.9747049  0.02529501]\n",
      "[0.9494277  0.05057232]\n",
      "[0.11283044 0.8871696 ]\n",
      "[0.05718328 0.94281673]\n",
      "[0.47425044 0.5257495 ]\n",
      "[0.02811126 0.9718888 ]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.908185   0.09181502]\n",
      "[0.97453415 0.0254658 ]\n",
      "[0.9731513  0.02684869]\n",
      "[0.07773572 0.9222643 ]\n",
      "[0.97385716 0.02614283]\n",
      "[0.0239483 0.9760517]\n",
      "[0.9731513  0.02684869]\n",
      "[0.97385716 0.02614283]\n",
      "[0.03570004 0.9642999 ]\n",
      "[0.03570004 0.9642999 ]\n",
      "[0.9731513  0.02684869]\n",
      "[0.02811126 0.9718888 ]\n",
      "[0.9742066 0.0257934]\n",
      "[0.80877846 0.19122158]\n",
      "[0.975155   0.02484501]\n",
      "[0.18921436 0.81078565]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.0203889  0.97961116]\n",
      "[0.3800386  0.61996144]\n",
      "[0.9736216  0.02637834]\n",
      "[0.10485352 0.8951464 ]\n",
      "[0.47425044 0.5257495 ]\n",
      "[0.10485352 0.8951464 ]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.80877846 0.19122158]\n",
      "[0.04181827 0.95818174]\n",
      "[0.9736216  0.02637834]\n",
      "[0.0667285  0.93327147]\n",
      "[0.97504324 0.02495677]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.9675194  0.03248058]\n",
      "[0.97459126 0.02540874]\n",
      "[0.83688617 0.16311382]\n",
      "[0.96382993 0.03617002]\n",
      "[0.3800386  0.61996144]\n",
      "[0.97373974 0.02626033]\n",
      "[0.04181827 0.95818174]\n",
      "[0.05290589 0.94709414]\n",
      "[0.9748746  0.02512534]\n",
      "[0.18921436 0.81078565]\n",
      "[0.936816   0.06318399]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.07773572 0.9222643 ]\n",
      "[0.97521067 0.02478931]\n",
      "[0.908185   0.09181502]\n",
      "[0.9742066 0.0257934]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.7032138  0.29678616]\n",
      "[0.96922505 0.03077491]\n",
      "[0.10485352 0.8951464 ]\n",
      "[0.9746482  0.02535182]\n",
      "[0.9740906  0.02590937]\n",
      "[0.18921436 0.81078565]\n",
      "[0.13736773 0.8626323 ]\n",
      "[0.13736773 0.8626323 ]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.7032138  0.29678616]\n",
      "[0.9740906  0.02590937]\n",
      "[0.97373974 0.02626033]\n",
      "[0.12154609 0.87845397]\n",
      "[0.0239483 0.9760517]\n",
      "[0.97459126 0.02540874]\n",
      "[0.02811126 0.9718888 ]\n",
      "[0.97373974 0.02626033]\n",
      "[0.0239483 0.9760517]\n",
      "[0.87828004 0.12171995]\n",
      "[0.80877846 0.19122158]\n",
      "[0.894353   0.10564696]\n",
      "[0.13736773 0.8626323 ]\n",
      "[0.01880888 0.9811911 ]\n",
      "[0.9740906  0.02590937]\n",
      "[0.25562602 0.744374  ]\n",
      "[0.05290589 0.94709414]\n",
      "[0.25562602 0.744374  ]\n",
      "[0.9742066 0.0257934]\n",
      "[0.3800386  0.61996144]\n",
      "[0.97443706 0.02556298]\n",
      "[0.9731513  0.02684869]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.9717415  0.02825852]\n",
      "[0.9743221  0.02567794]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.03864308 0.9613569 ]\n",
      "[0.94359726 0.05640272]\n",
      "[0.9675194  0.03248058]\n",
      "[0.97459126 0.02540874]\n",
      "[0.97245514 0.02754483]\n",
      "[0.9743221  0.02567794]\n",
      "[0.0203889  0.97961116]\n",
      "[0.95411354 0.04588649]\n",
      "[0.9581719  0.04182813]\n",
      "[0.02811126 0.9718888 ]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.96922505 0.03077491]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.9675194  0.03248058]\n",
      "[0.936816   0.06318399]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.29407382 0.70592624]\n",
      "[0.9675194  0.03248058]\n",
      "[0.9494277  0.05057232]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.05290589 0.94709414]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.3800386  0.61996144]\n",
      "[0.97385716 0.02614283]\n",
      "[0.97373974 0.02626033]\n",
      "[0.9743221  0.02567794]\n",
      "[0.9747049  0.02529501]\n",
      "[0.09737864 0.9026213 ]\n",
      "[0.9201306  0.07986944]\n",
      "[0.07773572 0.9222643 ]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.11283044 0.8871696 ]\n",
      "[0.9752662  0.02473373]\n",
      "[0.05290589 0.94709414]\n",
      "[0.47425044 0.5257495 ]\n",
      "[0.02594864 0.97405136]\n",
      "[0.33569655 0.6643035 ]\n",
      "[0.08384287 0.9161572 ]\n",
      "[0.29407382 0.70592624]\n",
      "[0.05718328 0.94281673]\n",
      "[0.01600082 0.9839992 ]\n",
      "[0.95411354 0.04588649]\n",
      "[0.9742066 0.0257934]\n",
      "[0.66139156 0.33860835]\n",
      "[0.7032138  0.29678616]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.86014414 0.13985585]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.06178394 0.9382161 ]\n",
      "[0.96382993 0.03617002]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.97521067 0.02478931]\n",
      "[0.09737864 0.9026213 ]\n",
      "[0.87828004 0.12171995]\n",
      "[0.9740906  0.02590937]\n",
      "[0.66139156 0.33860835]\n",
      "[0.94359726 0.05640272]\n",
      "[0.97443706 0.02556298]\n",
      "[0.07773572 0.9222643 ]\n",
      "[0.80877846 0.19122158]\n",
      "[0.936816   0.06318399]\n",
      "[0.9743221  0.02567794]\n",
      "[0.97443706 0.02556298]\n",
      "[0.0203889  0.97961116]\n",
      "[0.95411354 0.04588649]\n",
      "[0.08384287 0.9161572 ]\n",
      "[0.13736773 0.8626323 ]\n",
      "[0.04181827 0.95818174]\n",
      "[0.16137594 0.83862406]\n",
      "[0.0203889  0.97961116]\n",
      "[0.96572256 0.03427747]\n",
      "[0.42647776 0.5735222 ]\n",
      "[0.97453415 0.0254658 ]\n",
      "[0.9675194  0.03248058]\n",
      "[0.7032138  0.29678616]\n",
      "[0.05718328 0.94281673]\n",
      "[0.97385716 0.02614283]\n",
      "[0.9717415  0.02825852]\n",
      "[0.9581719  0.04182813]\n",
      "[0.01600082 0.9839992 ]\n",
      "[0.06178394 0.9382161 ]\n",
      "[0.9748182  0.02518177]\n",
      "[0.0667285  0.93327147]\n",
      "[0.9740906  0.02590937]\n",
      "[0.3800386  0.61996144]\n",
      "[0.06178394 0.9382161 ]\n",
      "[0.04181827 0.95818174]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.25562602 0.744374  ]\n",
      "[0.0239483 0.9760517]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.97476166 0.02523833]\n",
      "[0.02209866 0.97790134]\n",
      "[0.9739742  0.02602585]\n",
      "[0.04524204 0.9547579 ]\n",
      "[0.07203846 0.9279615 ]\n",
      "[0.97373974 0.02626033]\n",
      "[0.12154609 0.87845397]\n",
      "[0.7032138  0.29678616]\n",
      "[0.83688617 0.16311382]\n",
      "[0.908185   0.09181502]\n",
      "[0.9708439 0.0291561]\n",
      "[0.02594864 0.97405136]\n",
      "[0.0667285  0.93327147]\n",
      "[0.66139156 0.33860835]\n",
      "[0.05718328 0.94281673]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.936816   0.06318399]\n",
      "[0.9742066 0.0257934]\n",
      "[0.96382993 0.03617002]\n",
      "[0.0667285  0.93327147]\n",
      "[0.03044849 0.9695515 ]\n",
      "[0.97476166 0.02523833]\n",
      "[0.66139156 0.33860835]\n",
      "[0.16137594 0.83862406]\n",
      "[0.09737864 0.9026213 ]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.03864308 0.9613569 ]\n",
      "[0.97453415 0.0254658 ]\n",
      "[0.42647776 0.5735222 ]\n",
      "[0.97385716 0.02614283]\n",
      "[0.97493094 0.02506902]\n",
      "[0.47425044 0.5257495 ]\n",
      "[0.9752662  0.02473373]\n",
      "[0.96382993 0.03617002]\n",
      "[0.97385716 0.02614283]\n",
      "[0.0329734  0.96702665]\n",
      "[0.9675194  0.03248058]\n",
      "[0.97498715 0.02501284]\n",
      "[0.07773572 0.9222643 ]\n",
      "[0.9717415  0.02825852]\n",
      "[0.97498715 0.02501284]\n",
      "[0.01880888 0.9811911 ]\n",
      "[0.09038279 0.9096172 ]\n",
      "[0.83688617 0.16311382]\n",
      "[0.29407382 0.70592624]\n",
      "[0.96922505 0.03077491]\n",
      "[0.9746482  0.02535182]\n",
      "[0.9752662  0.02473373]\n",
      "[0.87828004 0.12171995]\n",
      "[0.0329734  0.96702665]\n",
      "[0.0329734  0.96702665]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.9708439 0.0291561]\n",
      "[0.97245514 0.02754483]\n",
      "[0.03864308 0.9613569 ]\n",
      "[0.04181827 0.95818174]\n",
      "[0.02594864 0.97405136]\n",
      "[0.9708439 0.0291561]\n",
      "[0.12154609 0.87845397]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.03570004 0.9642999 ]\n",
      "[0.05718328 0.94281673]\n",
      "[0.97504324 0.02495677]\n",
      "[0.9675194  0.03248058]\n",
      "[0.96572256 0.03427747]\n",
      "[0.0203889  0.97961116]\n",
      "[0.0667285  0.93327147]\n",
      "[0.04893184 0.9510682 ]\n",
      "[0.05718328 0.94281673]\n",
      "[0.01734913 0.9826508 ]\n",
      "[0.13736773 0.8626323 ]\n",
      "[0.06178394 0.9382161 ]\n",
      "[0.02594864 0.97405136]\n",
      "[0.16137594 0.83862406]\n",
      "[0.42647776 0.5735222 ]\n",
      "[0.0329734  0.96702665]\n",
      "[0.03570004 0.9642999 ]\n",
      "[0.66139156 0.33860835]\n",
      "[0.9743221  0.02567794]\n",
      "[0.01600082 0.9839992 ]\n",
      "[0.22063407 0.7793659 ]\n",
      "[0.03570004 0.9642999 ]\n",
      "[0.570332   0.42966804]\n",
      "[0.97498715 0.02501284]\n",
      "[0.9201306  0.07986944]\n",
      "[0.16137594 0.83862406]\n",
      "[0.08384287 0.9161572 ]\n",
      "[0.9743221  0.02567794]\n",
      "[0.74188656 0.25811344]\n",
      "[0.9292805  0.07071944]\n",
      "[0.9748746  0.02512534]\n",
      "[0.9292805  0.07071944]\n",
      "[0.6168865 0.3831135]\n",
      "[0.66139156 0.33860835]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196,  14],\n",
       "       [ 10, 200]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the confusion matrix\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[196  14]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = [\"No Side Effects\", \"Had Side Effects\"]\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title=\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
